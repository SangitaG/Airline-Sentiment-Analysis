{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the cleaned and processed dataset data together. I had to process and do EDA on two separate batches of data, to avoid performance issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/GA_DSI/Projects/capstone\n"
     ]
    }
   ],
   "source": [
    "cd '/home/jovyan/GA_DSI/Projects/capstone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lib.general_utilities as gu\n",
    "\n",
    "data_out_dir = 'data/processed_dataset_df/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read my pickled dataframes, with processed and cleaned text. I split the data processing\n",
    "# into 2 parts since kernel kept dying. I will append them together now. \n",
    "# note: need to reset index.\n",
    "filename1 = 'data/pickled/EDA_NB1_no_emoji_encoding/airline_cl_process_dataset_df1'\n",
    "filename2 = 'data/pickled/EDA_NB2_no_emoji_encoding/airline_cl_process_dataset_df2'\n",
    "df1 = gu.read_pickle_obj(filename1)\n",
    "df2 = gu.read_pickle_obj(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append dataframes.\n",
    "air_full_df = df1.append(df2)\n",
    "# fix index.\n",
    "air_full_df.reset_index(inplace=True)\n",
    "# drop column 'index' added by pandas, not needed.\n",
    "air_full_df.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "col_order = ['airline', 'airline_sentiment', 'text', 'clean_text', 'stopw_clean_text',\n",
    "             'stem_stopw_clean_text', 'negativereason', 'airline_sentiment_confidence']\n",
    "\n",
    "# set column order\n",
    "air_full_df = air_full_df[col_order]\n",
    "# pickle appended dataframe.\n",
    "gu.pickle_obj(data_out_dir+'airline_proc_dataset_70percCL_noEmEnc_df', air_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>stopw_clean_text</th>\n",
       "      <th>stem_stopw_clean_text</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>it was amazing and arrived an hour early youre...</td>\n",
       "      <td>amazing arrived hour early youre good</td>\n",
       "      <td>amaz arriv hour earli your good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>i lt3 pretty graphics so much better than mini...</td>\n",
       "      <td>lt3 pretty graphics better minimal iconography d</td>\n",
       "      <td>lt3 pretti graphic better minim iconographi d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "      <td>this is such a great deal already thinking abo...</td>\n",
       "      <td>great deal thinking 2nd trip amp havent gone 1...</td>\n",
       "      <td>great deal think 2nd trip amp havent gone 1st ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "      <td>thanks</td>\n",
       "      <td>thanks</td>\n",
       "      <td>thank</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica So excited for my first cross c...</td>\n",
       "      <td>so excited for my first cross country flight l...</td>\n",
       "      <td>excited cross country lax mco ive heard great ...</td>\n",
       "      <td>excit cross countri lax mco ive heard great th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç</td>\n",
       "      <td>i ‚ù§Ô∏è flying ‚ò∫Ô∏èüëç</td>\n",
       "      <td>‚ù§Ô∏è flying ‚ò∫Ô∏èüëç</td>\n",
       "      <td>‚ù§Ô∏è fli ‚ò∫Ô∏èüëç</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica you know what would be amazingl...</td>\n",
       "      <td>you know what would be amazingly awesome bosfl...</td>\n",
       "      <td>know amazingly awesome bosfll want fly</td>\n",
       "      <td>know amazingli awesom bosfll want fli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           airline airline_sentiment  \\\n",
       "4   Virgin America          positive   \n",
       "5   Virgin America          positive   \n",
       "6   Virgin America          positive   \n",
       "7   Virgin America          positive   \n",
       "8   Virgin America          positive   \n",
       "10  Virgin America          positive   \n",
       "11  Virgin America          positive   \n",
       "\n",
       "                                                 text  \\\n",
       "4   @VirginAmerica it was amazing, and arrived an ...   \n",
       "5   @VirginAmerica I &lt;3 pretty graphics. so muc...   \n",
       "6   @VirginAmerica This is such a great deal! Alre...   \n",
       "7                              @VirginAmerica Thanks!   \n",
       "8   @VirginAmerica So excited for my first cross c...   \n",
       "10                    I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç   \n",
       "11  @VirginAmerica you know what would be amazingl...   \n",
       "\n",
       "                                           clean_text  \\\n",
       "4   it was amazing and arrived an hour early youre...   \n",
       "5   i lt3 pretty graphics so much better than mini...   \n",
       "6   this is such a great deal already thinking abo...   \n",
       "7                                              thanks   \n",
       "8   so excited for my first cross country flight l...   \n",
       "10                                    i ‚ù§Ô∏è flying ‚ò∫Ô∏èüëç   \n",
       "11  you know what would be amazingly awesome bosfl...   \n",
       "\n",
       "                                     stopw_clean_text  \\\n",
       "4               amazing arrived hour early youre good   \n",
       "5    lt3 pretty graphics better minimal iconography d   \n",
       "6   great deal thinking 2nd trip amp havent gone 1...   \n",
       "7                                              thanks   \n",
       "8   excited cross country lax mco ive heard great ...   \n",
       "10                                      ‚ù§Ô∏è flying ‚ò∫Ô∏èüëç   \n",
       "11             know amazingly awesome bosfll want fly   \n",
       "\n",
       "                                stem_stopw_clean_text negativereason  \\\n",
       "4                     amaz arriv hour earli your good            NaN   \n",
       "5       lt3 pretti graphic better minim iconographi d            NaN   \n",
       "6   great deal think 2nd trip amp havent gone 1st ...            NaN   \n",
       "7                                               thank            NaN   \n",
       "8   excit cross countri lax mco ive heard great th...            NaN   \n",
       "10                                         ‚ù§Ô∏è fli ‚ò∫Ô∏èüëç            NaN   \n",
       "11              know amazingli awesom bosfll want fli            NaN   \n",
       "\n",
       "    airline_sentiment_confidence  \n",
       "4                            1.0  \n",
       "5                            1.0  \n",
       "6                            1.0  \n",
       "7                            1.0  \n",
       "8                            1.0  \n",
       "10                           1.0  \n",
       "11                           1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read it in to test.\n",
    "df = gu.read_pickle_obj(data_out_dir+'airline_proc_dataset_70percCL_noEmEnc_df')\n",
    "\n",
    "df[df.airline_sentiment=='positive'][:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emojis show up in processed text, checks they were not specially encoded. Now lets put the data together where I encoded the emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read my pickled dataframes, with processed and cleaned text. I split the data processing\n",
    "# into 2 parts since kernel kept dying. I will append them together now. \n",
    "# note: need to reset index.\n",
    "filename1 = 'data/pickled/EDA_NB1_emoji_encoding/airline_cl_process_dataset_df1'\n",
    "filename2 = 'data/pickled/EDA_NB2_emoji_encoding/airline_cl_process_dataset_df2'\n",
    "df1 = gu.read_pickle_obj(filename1)\n",
    "df2 = gu.read_pickle_obj(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append dataframes.\n",
    "air_full_df = df1.append(df2)\n",
    "# fix index.\n",
    "air_full_df.reset_index(inplace=True)\n",
    "# drop column 'index' added by pandas, not needed.\n",
    "air_full_df.drop(['index'], axis=1, inplace=True)\n",
    "\n",
    "col_order = ['airline', 'airline_sentiment', 'text', 'clean_text', 'stopw_clean_text',\n",
    "             'stem_stopw_clean_text', 'emojis', 'negativereason', 'airline_sentiment_confidence']\n",
    "\n",
    "# set column order\n",
    "air_full_df = air_full_df[col_order]\n",
    "# pickle appended dataframe.\n",
    "gu.pickle_obj(data_out_dir+'airline_proc_dataset_70percCL_withEmEnc_df', air_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>stopw_clean_text</th>\n",
       "      <th>stem_stopw_clean_text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>it was amazing and arrived an hour early youre...</td>\n",
       "      <td>amazing arrived hour early youre good</td>\n",
       "      <td>amaz arriv hour earli your good</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>i lt3 pretty graphics so much better than mini...</td>\n",
       "      <td>lt3 pretty graphics better minimal iconography d</td>\n",
       "      <td>lt3 pretti graphic better minim iconographi d</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "      <td>this is such a great deal already thinking abo...</td>\n",
       "      <td>great deal thinking 2nd trip havent gone 1st t...</td>\n",
       "      <td>great deal think 2nd trip havent gone 1st trip p</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "      <td>thanks</td>\n",
       "      <td>thanks</td>\n",
       "      <td>thank</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica So excited for my first cross c...</td>\n",
       "      <td>so excited for my first cross country flight l...</td>\n",
       "      <td>excited cross country lax mco ive heard great ...</td>\n",
       "      <td>excit cross countri lax mco ive heard great th...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç</td>\n",
       "      <td>i  EMOJI_1Ô∏è flying  EMOJI_2Ô∏è EMOJI_3</td>\n",
       "      <td>EMOJI_1Ô∏è flying EMOJI_2Ô∏è EMOJI_3</td>\n",
       "      <td>emoji_1Ô∏è fli emoji_2Ô∏è emoji_3</td>\n",
       "      <td>‚ù§ ‚ò∫ üëç</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Virgin America</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica you know what would be amazingl...</td>\n",
       "      <td>you know what would be amazingly awesome bosfl...</td>\n",
       "      <td>know amazingly awesome bosfll want fly</td>\n",
       "      <td>know amazingli awesom bosfll want fli</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           airline airline_sentiment  \\\n",
       "4   Virgin America          positive   \n",
       "5   Virgin America          positive   \n",
       "6   Virgin America          positive   \n",
       "7   Virgin America          positive   \n",
       "8   Virgin America          positive   \n",
       "10  Virgin America          positive   \n",
       "11  Virgin America          positive   \n",
       "\n",
       "                                                 text  \\\n",
       "4   @VirginAmerica it was amazing, and arrived an ...   \n",
       "5   @VirginAmerica I &lt;3 pretty graphics. so muc...   \n",
       "6   @VirginAmerica This is such a great deal! Alre...   \n",
       "7                              @VirginAmerica Thanks!   \n",
       "8   @VirginAmerica So excited for my first cross c...   \n",
       "10                    I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç   \n",
       "11  @VirginAmerica you know what would be amazingl...   \n",
       "\n",
       "                                           clean_text  \\\n",
       "4   it was amazing and arrived an hour early youre...   \n",
       "5   i lt3 pretty graphics so much better than mini...   \n",
       "6   this is such a great deal already thinking abo...   \n",
       "7                                              thanks   \n",
       "8   so excited for my first cross country flight l...   \n",
       "10               i  EMOJI_1Ô∏è flying  EMOJI_2Ô∏è EMOJI_3   \n",
       "11  you know what would be amazingly awesome bosfl...   \n",
       "\n",
       "                                     stopw_clean_text  \\\n",
       "4               amazing arrived hour early youre good   \n",
       "5    lt3 pretty graphics better minimal iconography d   \n",
       "6   great deal thinking 2nd trip havent gone 1st t...   \n",
       "7                                              thanks   \n",
       "8   excited cross country lax mco ive heard great ...   \n",
       "10                   EMOJI_1Ô∏è flying EMOJI_2Ô∏è EMOJI_3   \n",
       "11             know amazingly awesome bosfll want fly   \n",
       "\n",
       "                                stem_stopw_clean_text emojis negativereason  \\\n",
       "4                     amaz arriv hour earli your good                   NaN   \n",
       "5       lt3 pretti graphic better minim iconographi d                   NaN   \n",
       "6    great deal think 2nd trip havent gone 1st trip p                   NaN   \n",
       "7                                               thank                   NaN   \n",
       "8   excit cross countri lax mco ive heard great th...                   NaN   \n",
       "10                      emoji_1Ô∏è fli emoji_2Ô∏è emoji_3  ‚ù§ ‚ò∫ üëç            NaN   \n",
       "11              know amazingli awesom bosfll want fli                   NaN   \n",
       "\n",
       "    airline_sentiment_confidence  \n",
       "4                            1.0  \n",
       "5                            1.0  \n",
       "6                            1.0  \n",
       "7                            1.0  \n",
       "8                            1.0  \n",
       "10                           1.0  \n",
       "11                           1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read it in to test.\n",
    "df = gu.read_pickle_obj(data_out_dir+'airline_proc_dataset_70percCL_withEmEnc_df')\n",
    "\n",
    "df[df.airline_sentiment=='positive'][:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emojis show up in processed text, checks they are specially encoded. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
