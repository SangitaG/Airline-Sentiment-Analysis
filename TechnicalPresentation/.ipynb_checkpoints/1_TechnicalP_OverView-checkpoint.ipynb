{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ò∫Ô∏è üõ´ ‚ò∫Ô∏è  Airline Sentiment Classification  üòû üõ¨ üòû\n",
    "## Performed sentiment analysis, using Natural Language Processing (NLP) techniques, to classify airline customer tweets.\n",
    "### General Assembly Data Science Immersive Program Technical Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description from Kaggle:\n",
    "1. The Kaggle Dataset contains tweets and categories for `14,640k airline related tweets`,\n",
    "classified into one of `3 sentiment categories:` **(positive, negative, neutral)**.<br>\n",
    "2. Tweets were scraped from February of 2015 and contributors were asked to classify tweets into positive, negative, and neutral categories.<br>\n",
    "3. They were also asked to categorize the negative category tweets into negative reason topics (such as ‚Äúlate flight‚Äù or ‚Äúrude service‚Äù)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "This data science problem aims to help airline companies determine customer satisfaction,\n",
    "through feedback from twitter data.<br>\n",
    "\n",
    "### Project Goal \n",
    "\n",
    "To use the airline sentiment dataset, from kaggle, and pulled customer feedback from twitter,\n",
    "to evaluate if machine learning<br> techiques can achieve the following two tasks, and if so how well.<br>\n",
    "1. Predictive text sentiment classification.\n",
    "2. Topic inference from unknown text, through unsupervised learning models, such as LDA.<br>\n",
    "   (This portion of the project is still in progress).\n",
    "\n",
    "### Challenges\n",
    "- Text language can be very challenging to classify, due to the ambiguity and subjectivity, in the data.<br>\n",
    "- This is specially true for social media based feedback, via twitter.<br>\n",
    "- Furthermore twitter users use a lot of figurative language, emojis, abbreviations and so on.\n",
    "- There is also not much classified airline sentiment data available, so training models in a supervised manner,<br> with a substantial amount of data is difficult. This may affect the models performance in generalizing well to unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What have I done so far?\n",
    "\n",
    "1. <b>Exploration and Analysis of the data</b>:\n",
    "   1. Standardized case (to lower)\n",
    "   2. Removed puntuations\n",
    "   3. Removed stop words\n",
    "   4. Normalized data using stemming/lemmatization.\n",
    "      1. Lemmatization: look for base of the word.<br>\n",
    "       am, are, is <b>==></b> be<br> \n",
    "       car, cars, car's, cars' <b>==></b> car\n",
    "      2. Stemming: chops off the end of words based on certain alogithms.<br>\n",
    "        The most common seems to be Porter's algorithm.<br>\n",
    "        sses, ies, ss, s <b>==></b> ss, i, s, ''<br>\n",
    "        caresses, ponies, caress, cats <b>==></b> caress, poni, caress, cat\n",
    "   5. Encoded emojis separately as individual features.\n",
    "      1. Extracted emojis from input text.\n",
    "      2. Unclumped emojis, since users group them together.<br>\n",
    "         `NOTE`: Can continue to further explore using group of emojis as features.\n",
    "      3. Created a dictionary of emojis and codes for all the emojis found in the dataset.<br>\n",
    "         `NOTE`: Can continue to further explore expanding the emoji features supported.<br>\n",
    "   6. Looked at effects of data dimensionality reduction by separately analyzing different levels of text \n",
    "      processing.<br> ('cleaned text', 'added removal of stopwords', 'added use of stemming', 'added use of \n",
    "      lemmatization')\n",
    "   7. Explored characteristics of different n-gram features, using CounVectorizer.<br>\n",
    "      Looked at the classifier words:\n",
    "      1. What are the top words for each category, with the different processed texts? \n",
    "         1. Made a wordcloud for each category.\n",
    "         2. Made bar charts of top 50 words for each category.<br>\n",
    "      `NOTE`: Can further explore this by using TfidfVectorizer to see the differences.<br><br>\n",
    "2. <b>Modeling</b>\n",
    "   1. What effects do emojis have on model predictions?\n",
    "      1. Created model pipelines for data with and without `emoji encoding`.<br>\n",
    "   2. What effects do different levels of text processing, which is a way of doing<br>\n",
    "      feature dimensionality reduction, have on model predictions?\n",
    "      1. Created model pipelines for different levels of text processing.\n",
    "   3. Used `CountVectorizer` to transform the text data.<br>\n",
    "      `NOTE`: Can continue to further explore using TfidfVectorizer,<br>\n",
    "      to see which performs better as a preprocessing step.\n",
    "   4. Tested out two classifiers: `NaiveBayes` and `Logistic Regression`, using cross validation.\n",
    "      1. Why did I choose these two classifiers?<br>\n",
    "         From my understanding both have differnt learning mechanisms:<br>\n",
    "         <b>Naive Bayes</b>:<br>\n",
    "         Naive Bayes models the joint distribution (X,Y) and then predicting the<br>\n",
    "         probability P(y| x) where X is the set of inputs features and Y is the output labels.<br>\n",
    "         Basically it uses the training data to estimate P(X|Y) and P(Y). It then uses<br>\n",
    "         these together with bayes rule P(Y|X)=P(X|Y)*P(Y)/P(X), to predict a Y for a<br>\n",
    "         new X.<br>\n",
    "         <b>Logistic Regression</b>:<br>\n",
    "         Logistic regression directly models the P(y|x) from learning the input to output mapping,<br>\n",
    "         by minimizing the prediction.\n",
    "   5. Ran a gridsearch to find the best model for each classifier, by tunning hyper parameters.\n",
    "      1. Did grid searching improve the results?\n",
    "   6. Model evaluation.\n",
    "      1. Evaluated the classifiers by analyzing `accuracy`, `precision` and `recall` metrics,<br>\n",
    "         using confusion matrix and classification report.\n",
    "      1. What effects did different dimensionality reduction and preprocessing<br>\n",
    "         methods have on the results?<br><br>\n",
    "3. <b>LDA (Latent Dirichlet allocation) topic modeling.</b>\n",
    "   1. Given a corpus of text, what topics can be extracted from it?\n",
    "      1. Created LDA models using Gensim and Sklearn to see what topics<br>\n",
    "         were learned from the text. (used text processed using stopwords and lemma)\n",
    "      2. Visualized topics generated from the training data.\n",
    "   2. Pulled tweets with hashtags of major US Airlines and trained LDA model<br>\n",
    "      to see what topics were learned from the data.\n",
    "     \n",
    "   (NOTE: LDA topic modeling is work in progress...)\n",
    "     \n",
    "### Next Step:     Dealing with class imbalance\n",
    "\n",
    "1.  Resample the most frequent class to have a similar size as the other classes.\n",
    "2.  Tune the penalty hyperparameter of Logistic Regression.\n",
    "3.  Evaluate other algorithms which deal well with imbalanced datasets.\n",
    "    1. Decision trees may perform well on imbalanced datasets. The splitting rules that look at the class \n",
    "       variable used in the creation of the trees, can force both classes to be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Next Notebook: EDA](2_TechnicalP_EDA.ipynb) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
