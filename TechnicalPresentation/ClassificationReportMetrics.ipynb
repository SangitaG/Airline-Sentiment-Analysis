{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in classification reports in sklearn format to see the average precision recall across classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/GA_DSI/Projects/capstone\n"
     ]
    }
   ],
   "source": [
    "cd '/home/jovyan/GA_DSI/Projects/capstone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.general_utilities as gu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the classification report for no emojis encoded, modelled with CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes clean text \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.80      0.99      0.89      1500\n",
      "    neutral       0.87      0.31      0.46       350\n",
      "   positive       0.90      0.55      0.68       304\n",
      "\n",
      "avg / total       0.83      0.82      0.79      2154\n",
      "\n",
      "LogisticRegression clean text \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.90      0.90      0.90      1500\n",
      "    neutral       0.65      0.65      0.65       350\n",
      "   positive       0.77      0.76      0.76       304\n",
      "\n",
      "avg / total       0.84      0.84      0.84      2154\n",
      "\n",
      "NaiveBayes remove stopwords \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.98      0.89      1500\n",
      "    neutral       0.79      0.31      0.45       350\n",
      "   positive       0.86      0.62      0.72       304\n",
      "\n",
      "avg / total       0.82      0.82      0.79      2154\n",
      "\n",
      "LogisticRegression remove stopwords \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.88      0.89      0.88      1500\n",
      "    neutral       0.58      0.55      0.57       350\n",
      "   positive       0.73      0.75      0.74       304\n",
      "\n",
      "avg / total       0.81      0.81      0.81      2154\n",
      "\n",
      "NaiveBayes applied stemming \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.98      0.89      1500\n",
      "    neutral       0.79      0.31      0.44       350\n",
      "   positive       0.86      0.62      0.72       304\n",
      "\n",
      "avg / total       0.82      0.82      0.79      2154\n",
      "\n",
      "LogisticRegression applied stemming \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.89      0.88      0.89      1500\n",
      "    neutral       0.58      0.58      0.58       350\n",
      "   positive       0.71      0.72      0.71       304\n",
      "\n",
      "avg / total       0.81      0.81      0.81      2154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/pickled/Modelling_NB3_70PercConf_noEmojiEncoding/CrossVal/benchmark_class_report_sklearn_ngrams1_1.obj'\n",
    "classrep = gu.read_pickle_obj(filename)\n",
    "\n",
    "for k,v in classrep.items():\n",
    "    print(k, '\\n', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the classification report for with emojis encoded, modelled with CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes clean text \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.81      0.99      0.89      1500\n",
      "    neutral       0.85      0.31      0.46       350\n",
      "   positive       0.91      0.57      0.70       304\n",
      "\n",
      "avg / total       0.83      0.82      0.79      2154\n",
      "\n",
      "LogisticRegression clean text \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.90      0.90      0.90      1500\n",
      "    neutral       0.65      0.66      0.66       350\n",
      "   positive       0.78      0.78      0.78       304\n",
      "\n",
      "avg / total       0.84      0.84      0.84      2154\n",
      "\n",
      "NaiveBayes remove stopwords \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.98      0.89      1500\n",
      "    neutral       0.80      0.32      0.46       350\n",
      "   positive       0.87      0.63      0.73       304\n",
      "\n",
      "avg / total       0.82      0.82      0.80      2154\n",
      "\n",
      "LogisticRegression remove stopwords \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.88      0.88      0.88      1500\n",
      "    neutral       0.56      0.56      0.56       350\n",
      "   positive       0.74      0.75      0.74       304\n",
      "\n",
      "avg / total       0.81      0.81      0.81      2154\n",
      "\n",
      "NaiveBayes applied stemming \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.98      0.89      1500\n",
      "    neutral       0.79      0.31      0.45       350\n",
      "   positive       0.86      0.64      0.74       304\n",
      "\n",
      "avg / total       0.82      0.82      0.80      2154\n",
      "\n",
      "LogisticRegression applied stemming \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.89      0.88      0.89      1500\n",
      "    neutral       0.59      0.59      0.59       350\n",
      "   positive       0.71      0.75      0.73       304\n",
      "\n",
      "avg / total       0.82      0.82      0.82      2154\n",
      "\n",
      "NaiveBayes lemmatized \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.98      0.89      1500\n",
      "    neutral       0.83      0.33      0.48       350\n",
      "   positive       0.87      0.62      0.73       304\n",
      "\n",
      "avg / total       0.83      0.83      0.80      2154\n",
      "\n",
      "LogisticRegression lemmatized \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.89      0.89      0.89      1500\n",
      "    neutral       0.59      0.60      0.60       350\n",
      "   positive       0.77      0.73      0.75       304\n",
      "\n",
      "avg / total       0.82      0.82      0.82      2154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/pickled/Modelling_NB3_70PercConf_withEmojiEncoding/CrossVal/benchmark_class_report_sklearn_ngrams1_1.obj'\n",
    "classrep = gu.read_pickle_obj(filename)\n",
    "\n",
    "for k,v in classrep.items():\n",
    "    print(k, '\\n', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the classification report for with emojis encoded, modelled with CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes clean text \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.90      0.94      0.92      1500\n",
      "    neutral       0.76      0.60      0.67       350\n",
      "   positive       0.82      0.80      0.81       304\n",
      "\n",
      "avg / total       0.86      0.87      0.86      2154\n",
      "\n",
      "LogisticRegression clean text \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.91      0.95      0.93      1500\n",
      "    neutral       0.78      0.71      0.75       350\n",
      "   positive       0.85      0.75      0.80       304\n",
      "\n",
      "avg / total       0.88      0.89      0.88      2154\n",
      "\n",
      "NaiveBayes remove stopwords \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.86      0.94      0.90      1500\n",
      "    neutral       0.69      0.45      0.55       350\n",
      "   positive       0.77      0.75      0.76       304\n",
      "\n",
      "avg / total       0.82      0.83      0.82      2154\n",
      "\n",
      "LogisticRegression remove stopwords \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.88      0.94      0.91      1500\n",
      "    neutral       0.73      0.57      0.64       350\n",
      "   positive       0.79      0.73      0.76       304\n",
      "\n",
      "avg / total       0.84      0.85      0.85      2154\n",
      "\n",
      "NaiveBayes applied stemming \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.86      0.93      0.89      1500\n",
      "    neutral       0.68      0.46      0.55       350\n",
      "   positive       0.78      0.78      0.78       304\n",
      "\n",
      "avg / total       0.82      0.83      0.82      2154\n",
      "\n",
      "LogisticRegression applied stemming \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.89      0.94      0.92      1500\n",
      "    neutral       0.74      0.59      0.66       350\n",
      "   positive       0.79      0.75      0.77       304\n",
      "\n",
      "avg / total       0.85      0.86      0.85      2154\n",
      "\n",
      "NaiveBayes lemmatized \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.88      0.94      0.91      1500\n",
      "    neutral       0.73      0.54      0.62       350\n",
      "   positive       0.79      0.76      0.78       304\n",
      "\n",
      "avg / total       0.84      0.85      0.84      2154\n",
      "\n",
      "LogisticRegression lemmatized \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.90      0.95      0.92      1500\n",
      "    neutral       0.75      0.62      0.68       350\n",
      "   positive       0.81      0.74      0.78       304\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'data/pickled/Modelling_NB3_70PercConf_withEmojiEncoding/GridSearch/benchmark_class_report_sklearn.obj'\n",
    "classrep = gu.read_pickle_obj(filename)\n",
    "\n",
    "for k,v in classrep.items():\n",
    "    print(k, '\\n', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
